\chapter{Trabalhos relacionados}\label{chapter:trabalhos-relacionados}

Todos os trabalhos descritos neste capítulo foram selecionados dentre os artigos analisados no mapeamento sistemático
da literatura \cite{de2017time} sendo considerados aqueles  estão enquadrados dentro da categoria de \textit{Decay} no que
se refere ao uso do tempo no algoritmo de recomendação, independente do domínio de aplicação. No total sete trabalhos
foram selecionados, sendo apenas um da área educacional.

\section{Fan et al. 2015}

O trabalho de \citeonline{fan2015modeling} realiza a recomendação de \textit{web services}, considerando a avaliação do serviço
através da medição do \textit{Quality of Service} (QoS). QoS considera características do serviço como tempo de resposta,
disponibilidade, taxa de serviço, etc. Os autores consideram que a capacidade de prever a qualidade de um serviço diminui
conforme o tempo que passou da última invocação desse serviço, devido a possíveis encerramentos do serviço, falhas na
rede, etc. Por isso, a recomendação de serviços dos autores combina técnicas de similaridade com uma função de
decaimento que considera que a QoS diminui com o passar do tempo. O modelo de decaimento proposto considera que as
invocações mais recentes de dois usuários a um serviço devem ter um impacto maior no cálculo da similaridade entre os
usuários. A função de decaimento de um item $k$ é definida na Equação \ref{eq:fan-funcao-decaimento}.

\begin{equation}
  \label{eq:fan-funcao-decaimento}
  f(t_{i,k}, t_{j,k}) = e^{-\alpha \left|t_{atual} - \Delta t \right|}
\end{equation}

Onde: $\alpha$ é o fator de decaimento; e $\Delta t$ é a variação de tempo combinando o acesso do usuários $u_i$ e $u_j$
e é calculada com a fórmula apresentada na Equação \ref{eq:fan-fator-decaimento}.

\begin{equation}
  \label{eq:fan-fator-decaimento}
  \Delta t = \frac{(\Delta t_i + \Delta t_j)}{2}
\end{equation}

Onde $\Delta t_i$ é o intervalo de tempo entre a invocação do serviço pelo usuário $u_i$ ao serviço e o tempo atual e
$\Delta t_j$ é o intervalo de tempo entre a invocação do mesmo serviço pelo usuário $u_j$ e o tempo atual. Assim, a
similaridade dos usuários  diminui quanto maior for o $\Delta t$.

A nota do serviço $k$ é considerada como a combinação do QoS com a função de decaimento e é calculada através da Equação \ref{eq:fan-avaliacao}.

\begin{equation}
  \label{eq:fan-avaliacao}
  r_{u_i, s_k, t} = r_{u_i, s_k} \cdot f(t_{i,k}, t_{j,k})
\end{equation}

Os autores utilizam a nota resultado da função apresentada anteriormente para calcular a similaridade dos itens utilizando
o coeficiente de Pearson. A Equação \ref{eq:fan-similaridade} apresenta o coeficiente de Pearson utilizado pelos autores
que considera a função de decaimento.

\begin{equation}
  \label{eq:fan-similaridade}
  sim(u_1, u_j, t) = \frac{\sum_{s_k \in w_{u_i, u_j}}{(r_{u_i, s_k, t} - \overline{r_{u_i}})(r_{u_j, s_k, t} - \overline{r_{u_j}})}}{\sum_{s_k \in w_{u_i, u_j}}{(r_{u_i, s_k, t} - \overline{r_{u_i}})}^2 \sum_{s_k \in w_{u_i, u_j}}{(r_{u_j, s_k, t} - \overline{r_{u_j}})}^2}
\end{equation}

Onde $w_{u_i, u_j}$ é um conjunto dos itens em comum invocados pelos usuários $u_i$ e $u_j$. Utilizando essa fórmula de
similaridade é possível calcular a similaridade entre os usuários e encontrar os que são mais similares.

A proposta dos autores considera também a localização desses usuários para calcular a similaridade. Quanto mais próximos
eles estão, mais similares eles são considerados.

Foram realizados experimentos com a base de dados WS-Dream comparando o algoritmo proposto com outros 6 algoritmos: Recomendação
considerando todos os usuários (RBA), Filtragem Colaborativa Usuário-Usuário utilizando a Correlação de Pearson (UPCC),
Filtragem Colaborativa Item-Item utilizando a Correlação de Pearson (IPCC), \textit{Context-Aware Service Recommender}
(CASR), Método que considera a preferência do usuário de acordo com a sua localização (CASR-UP) e UPCC que considera o
decaimento (ITRP-WS). A avaliação foi realizada utilizando uma estratégia \textit{offline} e as métricas utilizadas para
a comparação foram MAE e RMSE.

Primeiramente foi realizado um experimento verificando a influência dos paramêtros dos algoritmos. Esses parâmetros são
considerados para decidir quais são os itens considerados significantes, ou seja, depois de calculada nota prevista para
os itens, decidir qual o limite mínimo para que um item seja recomendado. O segundo experimento avaliou a influência da
proporção da base de treino e de teste no experimento. E por último, para os algoritmos que utilizavam a Filtragem
Colaborativa foi avaliado a influência da quantidade de k-vizinhos considerada na eficiência do algoritmo. Os resultados
desses experimentos mostraram que o algoritmo proposto foi melhor que os outros 6 algoritmos analisados.

\section{Luo et al. 2010}

O trabalho de \citeonline{luo2010context} propõe um modelo de recomendação sensível ao contexto para ambientes de
aprendizagem pervasivos. Esse modelo utiliza uma abordagem híbrida (baseada em conteúdo com filtragem colaborativa)
com uma personalização pelo contexto. Três tipos de contexto são definidos:

\begin{enumerate}
\item Contexto do aluno, que possui as seguintes dimensões: tipo de dispositivo, ambiente (localização), perfil
(informações pessoais como nome e afiliação), preferências (recursos pelo qual o aluno tem interesse), processo de
aprendizagem (histórico de materiais acessados), pedido de acesso (a recursos educacionais massivos).
\item Contexto do serviço, que possui as seguintes dimensões: ambiente (localização), perfil (nome, parâmetros,
retornos), QoS (parâmetros de qualidade do serviço, como carga de trabalho, reputação, disponibilidade, segurança, etc.).
\item Contexto do recurso, que segue o \textit{China ELearning Technology Standard} que define as dimensões de um recurso
educacional. Esse padrão define as dimensões como sendo: perfil (informações sobre o recurso como Título, Assunto,
Palavras-chave), criador (nome, organização), audiência (tipo de educação, nível de ensino).
\end{enumerate}

O modelo de recomendação proposto pode ser dividido em dois passos: \textit{Logic-Based Resource Relevant Degree} e
\textit{Situation-Based Recourse Relevant Degree}.

Na etapa do \textit{Logic-based Resource Relevant Degree} é feita uma análise do histórico de recursos acessados pelo aluno e as
suas preferências. Esse passo combina a abordagem baseada em conteúdo, filtragem colaborativa e os padrões sequenciais
de acesso.

A abordagem baseada em conteúdo considera as múltiplas dimensões dos recursos como assunto, assunto secundário, nível
de ensino, etc. Nessa abordagem, é inserido um conceito de \textit{Preference Energy} (PE) para refletir a variação do interesse
do usuário com o passar do tempo. O PE indica que o interesse de um usuário a um item acessado diminui com o passar do
tempo. Os autores definem a diminuição da PE pela fórmula apresentada na Equação \ref{eq:luo-preference-energy}.

\begin{equation}
  \label{eq:luo-preference-energy}
  PE_{attenuation}(x) = e^{- \lambda (x-1)}, com \ x \geqslant 1
\end{equation}

Onde $x$ é a ordem do recurso na lista de acessos do usuário e $\lambda$ é o parâmetro de decaimento. Esse valor do PE,
combinado com as avaliações feitas pelos usuários para os itens, são utilizadas para gerar uma \textit{Individual Preference Tree}
que auxilia o cálculo da similaridade dos recursos candidatos a serem recomendados.

A \textit{Individual Preference Tree} utilizada pela abordagem baseada em conteúdo também é considerada pelo algoritmo de
filtragem colaborativa definida pelos autores para encontrar os k-vizinhos mais similares. Dessa forma, não só usuários
que acessaram os mesmos itens podem ser considerados vizinhos (como na filtragem colaborativa tradicional), mas também
usuários que acessaram itens similares entre si (mesmo assunto, palavras-chave, etc.) e os avaliaram de forma similar.

O último método de recomendação utilizado pela etapa chamada \textit{Logic-based Resource Relevant Degree} utiliza os padrões
sequencias de acesso dos usuários aos recursos. O algoritmo utilizado para a mineração dos padrões sequencias é o
PrefixSpan, que procura sequências (ou subsequências) que apareceram em pelo menos $\mu$ acessos. Baseado na árvore de
padrões sequenciais resultantes do algoritmo de mineração, é calculado quais os itens mais prováveis de serem acessados
de acordo a sequência atual do usuário. A proposta dos autores define que o algoritmo de mineração de sequências deve
ser executado de forma \textit{offline}, para garantir a resposta em um tempo hábil.

A etapa de \textit{Logic-based Resource Relevant Degree} combina o conjunto de recursos recomendados dos três algoritmos
descritos, removendo da lista os recursos já acessados pelo usuário.

Na etapa de \textit{Situation-based Resource Relevant Degree} é considerado que mesmo um recurso que combine com as preferências
do usuário pode não ser adequados para a recomendação se o contexto do usuário (dispositivo, ambiente) não for adequado
para utilizar o recurso. Para isso, no contexto dos recursos é descrito quais os dispositivos no qual a utilização do
recurso é adequada e no contexto do usuário é descrito qual o dispositivo do usuário. Também é considerado o grau de
satisfação no tempo para acessar um determinado recurso. Isso pode ser calculado pelo tamanho do recurso e a velocidade
de internet do usuário. Combinando essas duas características é possível ter uma recomendação mais adequada a situação
atual do aluno.

O algoritmo de recomendação proposto pelos autores então calcula uma lista de recursos candidatos a recomendação
utilizando os algoritmos de \textit{Logic-Based Resource Relevant Degree} e remove dessa lista os recursos que não satisfaçam o
dispositivo do usuário e a satisfação mínima com o tempo de resposta esperado.

Esse algoritmo foi avaliado através de uma avaliação \textit{offline} utilizando o base de dados do Movielens, onde foram adicionados dados de
contexto às interações existentes na base. As métricas utilizadas para avaliar o algoritmo foram \textit{Precision}, Utilidade e
Validade (razão entre a quantidade de itens apropriados para o tipo de conexão do usuário e o total de itens existentes).
A avaliação foi feita em relação aos seguintes  algoritmos tradicionais de recomendação: Algoritmo Baseado em Conteúdo
utilizando o modelo de espaço vetorial, Filtragem Colaborativa combinando a abordagem Usuário-Usuário com a Item-Item, Abordagem
Híbrida. Em comparação aos algoritmos tradicionais o algoritmo proposto teve melhores resultados no
experimento realizado.

\section{Benčič e Bieliková 2012}

O sistema de recomendação proposto por \citeonline{bencic2012action} busca recomendar ações aos usuários no momento que
for propício, de acordo com o contexto do usuário, e não apenas quando uma ação do interesse do usuário é encontrada.
Uma ação se refere a qualquer coisa que seja utilizada pelo usuário final de uma aplicação.

O método proposto para a recomendação representa o contexto do usuário através de símbolos, onde cada símbolo é
composto de duas partes – onde uma representa a dimensão e a outra representa a situação particular. Por exemplo,
$Clima:Limpo$. Para cada símbolo do contexto do usuário é atribuído um valor no intervalo $(0, 1)$ que indica a convicção
de que o usuário está naquele contexto.

A convicção de que o usuário está em determinado contexto é observada de tempos em tempos. Esse intervalo depende da
velocidade de conexão do dispositivo do usuário, nível da bateria, etc. A convicção do usuário estar em determinado
contexto diminui com o passar o tempo (supondo que uma nova observação demore a acontecer). Por isso, os autores
utilizam uma função de decaimento para essa convicção conforme a Equação \ref{eq:bencic-conviccao}.

\begin{equation}
  \label{eq:bencic-conviccao}
  CF_t = \frac{CF_b}{(1+r)^t}
\end{equation}

Onde $CF_t$ é a convicção calculada em função do tempo $t$, $CF_b$ é a convicção base, $r$ é o fator de decaimento e $t$
é o tempo em horas passado desde a última observação.

As ações são modeladas através de um conjunto de regras. As regras são definidas automaticamente através do feedback do
usuário e são representadas pelos antecedentes (em que situação a regra se aplica) e a consequência (a ação associada
aquela situação). As regras também possuem um decaimento na convicção com o passar o tempo. Porém, nesse caso o
decaimento não é constante, como acontece para o decaimento da convicção do contexto do usuário. Para as regras, o fator
de decaimento é calculado para que a convicção não chegue a zero com muita ao acontecer um longo período sem observações.

Combinando as convicções nas regras criadas com as convicções no contexto do usuário, são encontradas as ações com
maior probabilidade de serem adequadas. O modelo de recomendação considera não apenas a última observação, mas sim uma
combinação das últimas observações e suas respectivas convicções (com o fator de decaimento aplicado).

A avaliação do sistema foi feita realizando simulações de possíveis interações de um usuário imaginário em um ambiente
de recomendação de notícias durante o período de um mês. Nessa simulação, o objetivo foi calcular as recomendações de
notícias para três perfis de usuários: um usuário que lê notícias todos os dias pela manhã; outra que lê notícias apenas
nas segundas pela manhã e sextas a noite; e outro que começa lendo as notícias apenas nas segundas pela manhã e muda o
seu comportamento com o passar do tempo para a leitura as sextas a noite. Os resultados mostraram que o método conseguiu
compreender o comportamento dos três tipos de usuário com um \textit{Precision} e um \textit{Recall} de quase 100\%.

\section{Hawalah e Fasli 2014}

O trabalho de \citeonline{hawalah2014utilizing} propõe um método de recomendação utilizando o contexto do usuário
representado através de ontologias. O algoritmo proposto pode se adequar a diversos domínios, de forma que o contexto
seja incorporado aos interesses do usuário independente do que são os itens que serão recomendados. Além disso, o método
considera não só o contexto atual do usuário, mas também os contextos capturados anteriormente. Os autores separam o
método em três fases: Extração da informação, Aprender o perfil do usuário e Personalização.

A etapa de Extração da informação é realizada por um agente de captura dos dados que é genérico o suficiente para ser
adaptado de acordo com o domínio. Em determinados domínios pode ser utilizado uma coleta perguntando explicitamente os
interesses e o contexto ao usuário, enquanto em outros domínios é mais adequado capturar de forma implícita pela
navegação do usuário.

A informação bruta capturada (seja de forma explícita ou implícita) é processada pelo agente extrator, responsável por
extrair informação de mais alto nível. Esse agente está associado a dois tipos de bases de conhecimento: ontologias e
taxonomias. O agente realiza um mapeamento dos itens que o usuário demonstrou interesse em conceitos da ontologia de
referência, enquanto também extrai dimensões do contexto de mais alto nível utilizando-se das taxonomias de contexto.

A segunda etapa, responsável por compreender o perfil do usuário, utiliza a abordagem de Pré-filtragem Contextual para
definir qual a parte do perfil do usuário é relevante. É utilizada um método de micro-perfis, onde as
informações do perfil do usuário (itens acessados, notas dadas) que aconteceram em contextos similares ao atual são
consideradas mais relevantes para a recomendação. Para isso, é calculado a importância dos conceitos em cada contexto
possível, de acordo com as informações do perfil do usuário. Nesse cálculo, é considerada a frequência com que o
conceito aparece naquele determinado contexto, bem como a frequência com que esse conceito aparece em outros contextos
e a frequência com que outros conceitos aparecem nesse contexto.

Ainda no cálculo da importância do conceito em determinado contexto, é considerado que os interesses do usuário podem
mudar com o tempo. Para isso, é incluído na fórmula o fator de Recência (do inglês \textit{Recency}), de forma que os interesses
demonstrados pelo usuário mais recentemente são considerados mais importantes. A fórmula apresentada na Equação
\ref{eq:hawalah-recencia} apresenta o cálculo da recência.

\begin{equation}
  \label{eq:hawalah-recencia}
  Recency(c_j, ce_l) = \frac{1}{(1+\log(d_t - d_l) \times \alpha)}
\end{equation}

Onde $d_t$ é a data de inicialização do cálculo, $d_l$ é a data da última ocorrência do conceito $c_j$ no contexto
$ce_l$ e $\alpha$ é o fator de decaimento.

Dessa forma, como resultado dessa etapa temos os interesses do usuário em cada contexto e o peso de cada um. Essas
informações são utilizadas para construir ontologias de perfil contextual personalizada (CPOP, do inglês, \textit{Contextual
Personalized Ontology Profile}), sendo uma CPOP para cada contexto.

Na terceira etapa de personalização, a ontologia gerada na etapa anterior é utilizada para inferir outros conceitos que
o usuário pode ter interesse, além dos já presentes do seu perfil. Isso é realizado utilizando a técnica de \textit{Spreading
Activation}, que explora as ontologias buscando encontrar os novos conceitos relacionados ao perfil do usuário.
Utilizando essa técnica, é gerada uma lista de recomendações para cada CPOP, que são combinadas para gerar a lista
final de recomendações para o usuário.

A avaliação do trabalho de \citeonline{hawalah2014utilizing} foi através de um Estudo com Usuários, visando uma
avaliação centrada no usuário como descrito por \citeonline{kelly2009methods}. O objetivo da avaliação é verificar se
a recomendação contextual proposta no trabalho fornece uma recomendação mais eficiente do que os métodos tradicionais.
24 usuários participaram da avaliação, onde eles utilizaram um sistema por 30 dias, numa estratégia
\textit{Between-subjects}, i.e., cada grupo testa apenas uma versão do sistema. No total, 4 versões do sistema foram
testadas: o algoritmo proposto (CAPS), o algoritmo proposto sem o uso do contexto (CAPS-C), um método de recomendação
personalizado tradicional chamado pelos autores de Simple-P e um método de recomendação não personalizado chamado de Non-P.

O resultado da avaliação analisou a nota dada pelos usuários para os itens em uma escala de likert de 1 a 4. Sendo itens
com grau 1 e 2 considerados uma recomendação ruim e os itens com grau 3 e 4 considerados uma boa recomendação. Com isso
foi possível calcular a \textit{Precision at N} (P@N). O algoritmo proposto possui o melhor resultado de P@N entre os
algoritmos testados.

\section{Qiao e Zhang 2012}

O trabalho de \citeonline{qiao2015personalized} propõe um algoritmo de recomendação que considera as informações
contextuais disponíveis em dispositivos móveis, como tempo, localização, tipo do dispositivo, etc. O algoritmo de
recomendação é genérico, ou seja, sem um domínio de aplicação definido.

O objetivo dos autores é combinar a Filtragem Colaborativa com o contexto do usuário, considerando a variação temporal
nos interesses do usuário. Para tal, são encontrados os k usuários com os interesses similares ao usuário atual,
considerando o contexto do usuário, através de técnicas de clusterização. Após encontrados os k vizinhos, utiliza-se
uma fórmula para a predição das notas para itens ainda não acessados pelo usuário com a incorporação de uma função
temporal, como apresentado na Equação \ref{eq:qiao-predicao}. Os itens com as notas previstas mais altas são
recomendados ao usuário.

\begin{equation}
  \label{eq:qiao-predicao}
  p_{u,i} = \overline{r_u} + \frac{\sum_{v \in U}{sim(u, v)(r_{u,i} - \overline{r_v})f(t_{ni})}}{\sum_{v \in U}{sim(u, v)f(t_{ni})}}
\end{equation}

Sendo $p_{u,i}$ a nota prevista do usuário $u$ para o item $i$, $\overline{r_u}$ a média das notas dadas pelos usuário
$u$, $sim(u, v)$ a similaridade entre o usuário $u$ e o seu vizinho $v$, $r_{u,i}$ o grau de interesse do usuário $u$
pelo item $i$, $t$ é o tempo passado desde que o usuário $u$ utilizou o item $i$. A função $f$ é a função
exponencial de decaimento que representa a diminuição do interesse do usuário por um determinado item. A função de
decaimento é definida na Equação \ref{eq:qiao-funcao-decaimento}.

\begin{equation}
  \label{eq:qiao-funcao-decaimento}
  f(t_{ni}) = e^{-t_{ni}}
\end{equation}

A avaliação desse algoritmo foi realizada utilizando a base do MovieLens – 100 K, através da métrica MAE. Quando
comparado a Filtragem Colaborativa tradicional o algoritmo proposto alcançou melhores resultados, ou seja, teve uma taxa de erro menor.

\section{Kushwaha et al. 2016}

O trabalho de \citeonline{kushwaha2016inclusion} propõe uma versão modifica da técnica de \textit{Joint Matrix Factorization}
para uso em um sistema de recomendação de músicas incorporado ao Last.fm. A proposta busca reduzir a esparsidade dos
dados e melhorar a qualidade das recomendações. Para isso, é incorporado informações como descrição dos itens, perfil
do usuário e o seu contexto na matriz das notas dadas pelos Usuários para os Itens comumente utilizada na Filtragem
Colaborativa. Assim, a matriz utilizada pelo algoritmo possui uma maior dimensionalidade e complexidade. A técnica de fatoração de
matrizes é essencial para reduzir a dimensão da matriz utilizada e permitir a extração de informações latentes importantes para a
recomendação.

Além disso, no algoritmo proposto por \citeonline{kushwaha2016inclusion} é considerado uma estratégia de \textit{tag-based
user similarity matrix}, i.e., uma variação da Filtragem Colaborativa que utiliza as tags colocadas pelos usuários nos Artistas
e Músicas como forma de comparar os usuários e encontrar os mais similares. Nessa estratétia é considerada a variação
temporal da informação. Os autores consideram o decaimento da importância das \textit{tags} colocadas pelo usuário nos
itens com o passar do tempo. A fórmula utilizada pelos autores para representar o decaimento foi baseada em
\citeonline{iofciu2009time}, que pode ser vista na Equação \ref{eq:kushwaha-funcao-decaimento}.

\begin{equation}
  \label{eq:kushwaha-funcao-decaimento}
  postScore_i = \lambda^{\Delta Time_i}
\end{equation}

Onde $postScore_i$ é a importância temporal da \textit{tag} $i$, $\lambda$ é o fator de decaimento, que deve ser menor do que 1
e foi utilizado por \citeonline{kushwaha2016inclusion} como 0.9 e $\Delta Time_i$ é o tempo passado desde a interação. Além disso,
é considerada a especificidade da \textit{tag} para a nota final da \textit{tag}. A fórmula da especificidade é definida
na Equação \ref{eq:kushwaha-especificidade}

\begin{equation}
  \label{eq:kushwaha-especificidade}
  tagSpecificity_i = \log(50+tagCount_i)
\end{equation}

Onde $tagSpecificity_i$ é o fator de especificidade da \textit{tag} e $tagCount_i$ representa quanta vezes a \textit{tag} foi adicionada
ao item $i$. A nota final da \textit{tag} é calculada conforme a Equação \ref{eq:kushwaha-nota-final}.

\begin{equation}
  \label{eq:kushwaha-nota-final}
  tagScore_i = \frac{\sum_1^n{postScore}}{tagSpecifity_i}
\end{equation}

A fórmula acima combina a importância temporal da \textit{tag} com a sua especificidade. A nota final da \textit{tag}
é incorporada na matriz latente resultado da fatoração de matrizes para servir como fator de decaimento para a importância
das \textit{tags}, representando a variação nos interesses do usuário.

O algoritmo proposto pelos autores foi avaliado utilizando uma base de dados do próprio Last.fm, combinado com a base de
dados do DBpedia para a captura de informações sobre os artistas, compositores e músicas. A avaliação considerou a
métrica RMSE para as previsões para as notas que o usuário daria para um determinado
item comparada com a nota real. Quando comparado com outros dois algoritmos de recomendação que incorporam
informação social para recomendação (chamados BPMFSR e Sorec), o algoritmo proposto por \citeonline{kushwaha2016inclusion} se saiu melhor em 3
das 6 condições de experimento realizadas.

\section{Wei, Khoury e Fong 2013}

\citeonline{wei2013web} descrevem uma proposta de recomendação que utiliza a Filtragem Colaborativa e que aplica um
decaimento temporal na importância das interações dos usuários. No trabalho, é proposto um serviço para a recomendação
de propagandas em redes sociais, que leva em consideração a confiança entre usuários, a reputação dos usuários e as
relações entre usuários. Os autores afirmam que usuários com uma recomendação gerada com base em usuários conhecidos
pelo usuário atual serão mais bem aceitas, assim como usuários no qual ele confia e nos usuários com alta reputação
(especialistas).

O algoritmo de recomendação considera que a importância da relação entre os usuários diminui gradativamente com o tempo.
Então, um comentário realizado hoje deve ter um peso maior que um comentário realizado há um mês atrás quando for
avaliada a relação entre dois usuários. O decaimento é incluído diretamente na fórmula utilizada para realizar a
comparação de similaridade entre dois itens, como pode ser visto a seguir na Equação \ref{eq:wei-similaridade}.

\begin{equation}
  \label{eq:wei-similaridade}
  s_{i,j}(t) = \frac{\sum_{u \in U_i^t \cap U_j^t}{(f_{ui}^\alpha(t) \cdot r_{ui})(f_{uj}^\alpha(t) \cdot r_{uj})}}{\sqrt{\sum_{u \in U_i^t}{(f_{ui}^\alpha(t) \cdot r_{ui})}^2 \sum_{u \in U_j^t}{(f_{uj}^\alpha(t) \cdot r_{uj})}^2}}
\end{equation}

Onde a função $f$ é definida pelos autores como relevância temporal do item e pode ser vista na Equação \ref{eq:wei-relevancia-temporal}

\begin{equation}
  \label{eq:wei-relevancia-temporal}
  f_{uj}^\alpha(t) = e^{- \alpha (t - t_{ui})}
\end{equation}

Onde fator $\alpha$ é responsável por controlar a taxa de decaimento, $t$ representa o tempo atual e $t_{ui}$ representa
o tempo no qual o usuário $u$ utilizou o item $i$.

Além do decaimento na relevância das relações entre os usuários, os autores também incluem a confiança entre os
usuários e a reputação de especialistas da área na fórmula de similaridade visando melhorar a qualidade das
recomendações.

O algoritmo proposto foi avaliado utilizando três bases de dados: MovieLens, Facebook e Delicious. O algoritmo foi
comparado a outros dois algoritmos: Filtragem Colaborativa usando correlação de Pearson e usando correlação de Pearson
com efeito temporal. As métricas utilizadas foram \textit{Mean Absolute Error} e \textit{Root Mean Square Deviation}.
Os resultados mostraram que o algoritmo proposto melhorou significativamente a qualidade das recomendações.

\section{Considerações sobre o capítulo}

Nesse capítulo foram apresentados sete trabalhos relacionados que utilizam Sistemas de Recomendação (SRs) com o uso do
\textit{Decay}. A tabela \ref{tab:comparacao-trabalhos-relacionados} apresenta um resumo dos trabalhos apresentados e uma comparação com
a proposta desse trabalho.

\begin{table}[hp]
\footnotesize
\caption[Comparação dos trabalhos relacionados]{Comparação dos trabalhos relacionados.}
\label{tab:comparacao-trabalhos-relacionados}
\centering
\begin{tabular}{|p{2cm}|p{2cm}|p{1.9cm}|p{1.6cm}|p{1.5cm}|p{1.7cm}|p{2.2cm}|}
  \hline
  \textbf{Trabalho} & \textbf{Domínio} & \textbf{Abordagem} & \textbf{Constante de decaimento} & \textbf{Tempo absoluto} & \textbf{Avaliação} & \textbf{Algoritmos comparados} \\
  \hline
  \citeonline{fan2015modeling} & \textit{Web Services} & Filtragem Colaborativa & Sim & Sim & Offline, com a base WS-Dream & RBA, UPCC, IPCC, CASR, CASR-UP e ITRP-WS \\
  \hline
  \citeonline{luo2010context} & AVA & Híbrida & Sim & Não & Offline, com a base do Movielens & Abordagens tradicionais: Baseada em Conteúdo, Filtragem Colaborativa e Híbrida \\
  \hline
  \citeonline{bencic2012action} & Genérico & Baseada em Conhecimento & Sim & Sim & Simulações & Nenhum \\
  \hline
  \citeonline{hawalah2014utilizing} & Genérico & Baseada em Conhecimento & Sim & Sim & Estudos com usuários, com 24 usuários durante 30 dias & CAPS-C, Simple-P e Non-P \\
  \hline
  \citeonline{qiao2015personalized} & Genérico & Filtragem Colaborativa & Não & Sim & Offline, com a base do Movielens & Filtragem Colaborativa tradicional \\
  \hline
  \citeonline{kushwaha2016inclusion} & Músicas & Híbrida & Sim & Sim & Offline, com a base da Last.fm & BPMFSR e Sorec \\
  \hline
  \citeonline{wei2013web} & Propagandas & Filtragem Colaborativa & Sim & Sim & Offline, com as bases do Movielens, Facebook e Delicious & Filtragem Colaborativa usando correlação de Pearson com e sem efeito temporal \\
  \hline
  Proposta & AVA & Baseada em Conteúdo & Não & Não & Estudos com usuários, com pelo menos 60 usuários durante 45 dias & Abordagem Baseada em Conteúdo tradicional \\
  \hline
\end{tabular}
\legend{Fonte: O autor.}
\end{table}

Pode-se observar que dos trabalhos relacionados, apenas um é da área educacional, enquanto os outros são aplicados em outros
domínios de aplicação. Além disso, nenhum dos trabalhos apresentados utiliza a abordagem Baseada em Conteúdo. A
abordagem mais comumente utilizada nos trabalhos relacionados é a Filtragem Colaborativa, aparecendo em três trabalhos
sozinhas e em mais dois outros trabalhos combinados com outras abordagens (Abordagem Híbrida).

Dos trabalhos relacionados, apenas um não considera uma Constante de decaimento. Essa Constante de decaimento geralmente
é um valor entre $0$ e $1$ que define a velocidade com que o peso das interações do usuário diminui. Esse valor é definido
pelos autores de forma empírica, não tendo um método para a definição dessa constante. No trabalho de \citeonline{qiao2015personalized},
que não utiliza uma Constante de decaimento, é utilizada um função exponencial para o decaimento do interesse do usuário. Na
proposta do presente trabalho também não é utiliza uma Constante de decaimento e é utilizada um função de decaimento linear.

Também é possível observar que apenas um trabalho não utiliza o Tempo absoluto na função de decaimento. Isso significa que
a maioria dos trabalhos relacionados considera o tempo passado (e.g., em segundos, minutos, horas, etc.) desde a interação
para calcular a importância desta. O trabalho de \citeonline{luo2010context} considera a sequência de itens acessados, dando
uma maior importância para os itens mais recentes de acordo com a posição do item na lista ordenada pelo tempo de acesso.
A proposta desse trabalho utiliza uma estratégia similar a de \citeonline{luo2010context} nesse aspecto.

Sobre a avaliação, pode-se observar que a maioria utiliza uma avaliação \textit{Offline}. \citeonline{bencic2012action} realiza
uma simulação para demonstrar o algoritmo de recomendação, que segundo a definição de \citeonline{shani2011evaluating} não
se encaixaria como uma avaliação de SR. O trabalho de \citeonline{luo2010context}, que é da área educacional assim como a
proposta desse trabalho, utiliza uma avaliação \textit{offline} com a base do Movielens \footnote{Base de dados com
notas dadas por usuários à filmes. Disponível em: https://grouplens.org/datasets/movielens/.}.
Essa avaliação, apesar de ser realizada de forma correta e apresentar bons resultados, não garante que o SR desenvolvido por \citeonline{luo2010context}
teria um bom resultado em um ambiente real de uso. Por isso, na proposta desse trabalho será realizada uma avaliação com
participação de usuários em um ambiente educacional durante uma situação real de uso.

Na avaliação citada anteriormente, o objetivo será comparar o algoritmo proposto neste trabalho com a abordagem Baseada
em Conteúdo tradicional. É possível observar pelos trabalhos relacionados que comparar a proposta com os algoritmos mais
tradicionais da área é algo comumente realizado \cite{fan2015modeling, luo2010context, hawalah2014utilizing, qiao2015personalized, wei2013web}.

